[
  { "id": "M6", "cat": "modeling", "q": "How is a Many-to-Many relationship resolved in a Relational Database?", "options": ["By placing a foreign key in the table with the highest cardinality", "By creating an Associative (Intersection) table", "By defining a recursive foreign key constraint on the parent entity", "By denormalizing the attributes of one entity into the other", "By utilizing an object-relational mapping (ORM) framework"], "a": 1, "expl": "M:N requires an intersection table to break it into two 1:N relationships.", "prep": "DMBOK2 Ch. 5: Relationships.", "ref": "DMBOK2 Ch. 5" },
  { "id": "M7", "cat": "modeling", "q": "In Crow's Foot notation, what does a 'Circle' symbol indicate on a relationship line?", "options": ["Mandatory participation in the relationship", "Optional existence (Zero or more)", "A mutually exclusive subtype relationship", "An identifying relationship where the child depends on the parent", "A recursive relationship back to the same entity"], "a": 1, "expl": "Circle = Zero (Optional). Line = One (Mandatory). Crow's foot = Many.", "prep": "DMBOK2 Ch. 5: Notation.", "ref": "DMBOK2 Ch. 5" },
  { "id": "M8", "cat": "modeling", "q": "Which Slowly Changing Dimension (SCD) type preserves history by adding a new row for each change?", "options": ["Type 1 (Overwrite)", "Type 2 (Add Row)", "Type 3 (Add Column)", "Type 4 (History Table)", "Type 6 (Hybrid)"], "a": 1, "expl": "Type 2 adds a new row to track full history. Type 1 overwrites.", "prep": "DMBOK2 Ch. 5: SCD Types.", "ref": "DMBOK2 Ch. 5" },
  { "id": "M9", "cat": "modeling", "q": "A Physical Data Model contains which specific detail NOT found in a Logical Data Model?", "options": ["Resolution of many-to-many relationships", "Primary and foreign key assignments", "DBMS-specific data types (e.g., VARCHAR2, INTEGER)", "Normalization to at least the Third Normal Form (3NF)", "Definitions of business rules and constraints"], "a": 2, "expl": "Physical models are tied to a specific technology implementation (Oracle, SQL Server, etc.).", "prep": "DMBOK2 Ch. 5: Model Levels.", "ref": "DMBOK2 Ch. 5" },
  { "id": "M10", "cat": "modeling", "q": "What is a 'Conformed Dimension'?", "options": ["A dimension that has been fully normalized to eliminate redundancy", "A dimension shared consistently across multiple Fact tables or Data Marts", "A dimension that contains only slowly changing attributes", "A dimension specifically designed to handle hierarchical data", "A dimension that is physically stored within the fact table"], "a": 1, "expl": "Conformed dimensions allow cross-functional analysis (Drill across).", "prep": "DMBOK2 Ch. 5: Conformed Dimensions.", "ref": "DMBOK2 Ch. 5" },
  { "id": "M11", "cat": "modeling", "q": "What is a 'Recursive Relationship'?", "options": ["A relationship that spans across multiple physical databases", "A relationship where an entity relates to itself (e.g., Employee manages Employee)", "A relationship that causes an infinite loop during query execution", "A relationship between a supertype and its corresponding subtypes", "A relationship that requires a bridge table to resolve"], "a": 1, "expl": "Example: Employee reports to Manager (who is also an Employee). Self-referencing.", "prep": "DMBOK2 Ch. 5: Relationships.", "ref": "DMBOK2 Ch. 5" },
  { "id": "M12", "cat": "modeling", "q": "Second Normal Form (2NF) specifically addresses:", "options": ["Transitive dependencies (non-key attributes depending on other non-key attributes)", "Partial dependencies (attributes dependent on only part of a composite key)", "Repeating groups (multi-valued attributes within a single record)", "Multi-valued dependencies requiring a separate table", "The elimination of all surrogate keys in favor of natural keys"], "a": 1, "expl": "2NF is relevant only for composite keys (removing partial dependency).", "prep": "DMBOK2 Ch. 5: Normalization.", "ref": "DMBOK2 Ch. 5" },
  { "id": "M13", "cat": "modeling", "q": "The 'Grain' of a fact table refers to:", "options": ["The specific hardware storage block size used by the database", "The level of detail represented by a single row", "The total number of foreign keys linking to dimension tables", "The frequency at which the ETL process updates the table", "The specific aggregation function (e.g., SUM, AVG) applied to the measures"], "a": 1, "expl": "Grain = Level of detail (e.g., Line Item vs Transaction Header vs Monthly Summary).", "prep": "DMBOK2 Ch. 5: Dimensional Modeling.", "ref": "DMBOK2 Ch. 5" },
  { "id": "M14", "cat": "modeling", "q": "Which of the following is a type of NoSQL data model?", "options": ["Dimensional", "Document Store", "Network", "Hierarchical", "Object-Relational"], "a": 1, "expl": "Document (JSON/XML), Key-Value, Column-Family, and Graph are NoSQL types.", "prep": "DMBOK2 Ch. 5: NoSQL.", "ref": "DMBOK2 Ch. 5" },
  { "id": "M15", "cat": "modeling", "q": "What is 'Reverse Engineering' in the context of data modeling?", "options": ["Generating Data Definition Language (DDL) scripts from a logical model", "Deriving a logical/conceptual model from an existing physical schema", "Converting a relational database schema into a NoSQL document structure", "Translating business requirements directly into a physical database design", "De-normalizing a 3NF model to create a dimensional star schema"], "a": 1, "expl": "Deriving the model from the physical implementation (Physical -> Logical).", "prep": "DMBOK2 Ch. 5: Reverse Engineering.", "ref": "DMBOK2 Ch. 5" },
  { "id": "M16", "cat": "modeling", "q": "A 'Supertype/Subtype' relationship is used to model:", "options": ["Inheritance (IS-A relationships) and shared/specific attributes", "Composition (HAS-A relationships) where the child cannot exist without the parent", "Recursive hierarchies such as organizational charts", "Many-to-Many relationships requiring an associative entity", "Time-variant data changes using Slowly Changing Dimensions"], "a": 0, "expl": "Common attributes in Supertype, specific attributes in Subtype.", "prep": "DMBOK2 Ch. 5: Subtyping.", "ref": "DMBOK2 Ch. 5" },
  { "id": "M17", "cat": "modeling", "q": "Which schema type looks like a 'Star' but has dimensions that are normalized into multiple tables?", "options": ["Data Vault Schema", "Snowflake Schema", "Fact Constellation Schema", "Third Normal Form (3NF) Schema", "Anchor Modeling Schema"], "a": 1, "expl": "Snowflake normalizes dimensions, creating branches/snowflakes.", "prep": "DMBOK2 Ch. 5: Snowflake.", "ref": "DMBOK2 Ch. 5" },
  { "id": "M18", "cat": "modeling", "q": "What is the primary key of a Fact Table typically composed of?", "options": ["A single, system-generated surrogate key", "A composite of the Foreign Keys from all participating dimensions", "The natural business key of the core transaction", "A combination of the transaction timestamp and the user ID", "A hash value calculated from all the measure columns"], "a": 1, "expl": "Fact PK is usually the composite of Dimension FKs.", "prep": "DMBOK2 Ch. 5: Fact Tables.", "ref": "DMBOK2 Ch. 5" },
  { "id": "Q1", "cat": "quality", "q": "Which Data Quality dimension measures whether data reflects the real-world object or event it represents?", "options": ["Validity", "Accuracy", "Consistency", "Reliability", "Precision"], "a": 1, "expl": "Accuracy = Matches reality. Validity = Matches defined format/domain.", "prep": "DMBOK2 Ch. 13: DQ Dimensions.", "ref": "DMBOK2 Ch. 13" },
  { "id": "Q2", "cat": "quality", "q": "What does the 'I' stand for in the DMAIC improvement cycle used in Six Sigma and Data Quality?", "options": ["Identify", "Improve", "Implement", "Investigate", "Integrate"], "a": 1, "expl": "Define, Measure, Analyze, Improve, Control.", "prep": "DMBOK2 Ch. 13: DMAIC.", "ref": "DMBOK2 Ch. 13" },
  { "id": "Q3", "cat": "quality", "q": "Data Profiling is BEST described as:", "options": ["The automated correction of identified data anomalies", "Assessing data content and structure to discover patterns and anomalies", "The process of mapping source data fields to target data fields", "Defining the business rules that govern data entry", "Monitoring data quality metrics on an ongoing dashboard"], "a": 1, "expl": "Profiling is the diagnostic step (Assessment), not the fix (Remediation).", "prep": "DMBOK2 Ch. 13: Profiling.", "ref": "DMBOK2 Ch. 13" },
  { "id": "Q4", "cat": "quality", "q": "If a mandatory 'Date of Birth' field is blank, which Data Quality dimension is primarily violated?", "options": ["Validity", "Completeness", "Consistency", "Accuracy", "Referential Integrity"], "a": 1, "expl": "Missing data (Nulls in mandatory fields) is a Completeness issue.", "prep": "DMBOK2 Ch. 13: DQ Dimensions.", "ref": "DMBOK2 Ch. 13" },
  { "id": "Q5", "cat": "quality", "q": "Which approach is considered the most cost-effective for managing Data Quality?", "options": ["Automated data cleansing during the ETL process", "Prevention at the source", "Periodic manual audits of critical data elements", "Implementing a robust Master Data Management (MDM) hub", "Outsourcing data remediation to a third-party vendor"], "a": 1, "expl": "The 1-10-100 rule: Prevention is cheaper than correction or failure.", "prep": "DMBOK2 Ch. 13: Cost of Quality.", "ref": "DMBOK2 Ch. 13" },
  { "id": "Q6", "cat": "quality", "q": "A 'Data Quality Rule' typically translates:", "options": ["Data profiling results into a data quality dashboard", "Business requirements into technical constraints", "Conceptual data models into logical data models", "Master data definitions into transactional system code", "Data governance policies into organizational change management plans"], "a": 1, "expl": "DQ Rules define what 'good' looks like technically based on business needs.", "prep": "DMBOK2 Ch. 13: DQ Rules.", "ref": "DMBOK2 Ch. 13" },
  { "id": "Q7", "cat": "quality", "q": "Which dimension measures the time lag between an event occurring and the data being available for use?", "options": ["Currency", "Timeliness", "Volatility", "Availability", "Latency"], "a": 1, "expl": "Timeliness concerns availability when needed (Latency).", "prep": "DMBOK2 Ch. 13: DQ Dimensions.", "ref": "DMBOK2 Ch. 13" },
  { "id": "Q8", "cat": "quality", "q": "Root Cause Analysis (RCA) in Data Quality aims to:", "options": ["Automatically correct data errors as they enter the system", "Identify the underlying reason for a defect to prevent recurrence", "Determine the financial impact of poor data quality", "Assign accountability to a specific Data Steward", "Profile the data to discover hidden anomalies"], "a": 1, "expl": "Fixing the root cause prevents the issue from returning (Systemic fix).", "prep": "DMBOK2 Ch. 13: RCA.", "ref": "DMBOK2 Ch. 13" },
  { "id": "Q9", "cat": "quality", "q": "ISO 8000 is the international standard specifically for:", "options": ["Information Security Management Systems (ISMS)", "Data Quality", "IT Service Management (ITSM)", "Records Management", "Quality Management Systems (QMS)"], "a": 1, "expl": "ISO 8000 = Data Quality. ISO 27001 = Security.", "prep": "DMBOK2 Ch. 13: Standards.", "ref": "DMBOK2 Ch. 13" },
  { "id": "Q10", "cat": "quality", "q": "Consistency implies that:", "options": ["Data values are equivalent across redundant or distributed systems", "Data accurately reflects the real-world object it represents", "Data conforms to the defined structural format and domain values", "Data is continuously available without interruption", "Data contains no null values in mandatory fields"], "a": 0, "expl": "Consistency = Absence of difference between redundant copies or related values.", "prep": "DMBOK2 Ch. 13: DQ Dimensions.", "ref": "DMBOK2 Ch. 13" },
  { "id": "Q11", "cat": "quality", "q": "What is the 'Golden Record'?", "options": ["The original source record before any transformations are applied", "The single, trusted, consolidated view of an entity (e.g., Customer)", "A record that has been verified by a human Data Steward", "The record containing the most recently updated attributes", "A mathematically perfect record with zero null values"], "a": 1, "expl": "Golden Record is the goal of MDM and Entity Resolution (Best version of truth).", "prep": "DMBOK2 Ch. 13/10.", "ref": "DMBOK2 Ch. 13" },
  { "id": "Q12", "cat": "quality", "q": "Data Cleansing typically involves:", "options": ["Identifying the root cause of data defects in source systems", "Standardizing, correcting, and validating data", "Defining the business rules for data quality measurement", "Designing the conceptual data model for a new application", "Archiving historical data to reduce database size"], "a": 1, "expl": "Cleansing repairs data (Parsing, Standardization, Enrichment).", "prep": "DMBOK2 Ch. 13: Cleansing.", "ref": "DMBOK2 Ch. 13" },
  { "id": "Q13", "cat": "quality", "q": "What is 'Data Validity'?", "options": ["Data accurately represents the real-world object or event", "Data conforms to the defined format, type, and range (Domain)", "Data values are consistent across all enterprise systems", "Data is complete and contains no missing values", "Data is current and reflects the most recent transactions"], "a": 1, "expl": "Validity = Matches defined format/domain (e.g., M/F for gender). Accuracy = Matches reality.", "prep": "DMBOK2 Ch. 13: DQ Dimensions.", "ref": "DMBOK2 Ch. 13" },
  { "id": "Q14", "cat": "quality", "q": "Statistical Process Control (SPC) is used in Data Quality to:", "options": ["Calculate the exact financial cost of poor data quality", "Monitor variations in data quality metrics over time to detect anomalies", "Automatically correct data errors using machine learning algorithms", "Determine the optimal sample size for manual data audits", "Map source data fields to target data warehouse dimensions"], "a": 1, "expl": "SPC monitors process stability using control charts.", "prep": "DMBOK2 Ch. 13: SPC.", "ref": "DMBOK2 Ch. 13" },
  { "id": "Q15", "cat": "quality", "q": "Which of the following is NOT a standard Data Quality dimension defined in DMBOK?", "options": ["Validity", "Uniqueness", "Reasonableness", "Cost", "Consistency"], "a": 3, "expl": "Cost is a metric of management, not a dimension of the data itself.", "prep": "DMBOK2 Ch. 13.", "ref": "DMBOK2 Ch. 13" },
  { "id": "Q16", "cat": "quality", "q": "The 'C' in the 'CIA Triad' of Security stands for Confidentiality. What does the 'C' in the 'FACT' (DQ Framework) usually refer to?", "options": ["Completeness", "Consistency", "Correctness", "Currency", "Clarity"], "a": 0, "expl": "Frameworks vary, but Completeness is a universal core dimension often represented by C.", "prep": "DMBOK2 Ch. 13.", "ref": "DMBOK2 Ch. 13" },
  { "id": "S1", "cat": "security", "q": "Which element of the CIA Triad ensures that data is not altered by unauthorized people?", "options": ["Confidentiality", "Integrity", "Availability", "Non-repudiation", "Authenticity"], "a": 1, "expl": "Integrity = No unauthorized alteration. Confidentiality = No unauthorized access.", "prep": "DMBOK2 Ch. 7: CIA Triad.", "ref": "DMBOK2 Ch. 7" },
  { "id": "S2", "cat": "security", "q": "What is the principle of 'Least Privilege'?", "options": ["Granting access based on a user's hierarchical rank in the organization", "Granting only the minimum access necessary to perform a job function", "Ensuring all users have read-only access to enterprise data by default", "Requiring multi-factor authentication for all administrative accounts", "Restricting access to data only during standard business hours"], "a": 1, "expl": "Least Privilege reduces the attack surface and risk of accidental damage.", "prep": "DMBOK2 Ch. 7: Principles.", "ref": "DMBOK2 Ch. 7" },
  { "id": "S3", "cat": "security", "q": "Which control allows a user to prove who they are?", "options": ["Authorization", "Authentication", "Accounting", "Non-repudiation", "Encryption"], "a": 1, "expl": "Authentication = Identity verification (Who you are). Authorization = Permissions (What you can do).", "prep": "DMBOK2 Ch. 7: AAA.", "ref": "DMBOK2 Ch. 7" },
  { "id": "S4", "cat": "security", "q": "GDPR gives EU citizens the 'Right to Erasure', commonly known as:", "options": ["Right to be Forgotten", "Right to Data Portability", "Right to Restrict Processing", "Right to Object", "Right to Rectification"], "a": 0, "expl": "Right to be Forgotten is the common name for GDPR Art 17.", "prep": "DMBOK2 Ch. 7: GDPR.", "ref": "DMBOK2 Ch. 7" },
  { "id": "S5", "cat": "security", "q": "Data Masking is primarily used for:", "options": ["Encrypting production data to prevent unauthorized access by DBAs", "Protecting sensitive data in non-production (dev/test) environments", "Ensuring data integrity during transmission over public networks", "Anonymizing data permanently for public release", "Hashing passwords for secure storage in the database"], "a": 1, "expl": "Masking obfuscates PII so developers/testers can work without seeing real sensitive data.", "prep": "DMBOK2 Ch. 7: Masking.", "ref": "DMBOK2 Ch. 7" },
  { "id": "S6", "cat": "security", "q": "Which cryptographic technique is 'One-way' (cannot be reversed)?", "options": ["Symmetric Encryption", "Asymmetric Encryption", "Hashing", "Tokenization", "Data Masking"], "a": 2, "expl": "Hashing is irreversible (e.g., for passwords). Encryption is reversible (with a key).", "prep": "DMBOK2 Ch. 7: Encryption.", "ref": "DMBOK2 Ch. 7" }
]
