[
  { "id": "NG1", "cat": "governance", "q": "Which body acts as the steering committee that establishes standards and holds the highest level of authority for approving data policies?", "options": ["Data Governance Board", "Data Governance Office", "Data Stewards Council", "IT Steering Committee", "Enterprise Architecture Board"], "a": 0, "expl": "The Data Governance Board acts as the steering committee that establishes standards and ensures enterprise-wide compliance.", "prep": "DMBOK2 Ch. 3: Data Governance Board = highest authority for policies.", "ref": "DMBOK2 Ch. 3" },
  { "id": "NG2", "cat": "governance", "q": "Who handles the daily administration of the data governance program and ensures that policies are communicated and followed throughout the organization?", "options": ["Data Governance Officer", "Chief Data Officer", "Lead Data Steward", "Data Owner", "Compliance Officer"], "a": 0, "expl": "The Data Governance Officer handles the daily administration of the program.", "prep": "DMBOK2 Ch. 3: DGO = daily administration.", "ref": "DMBOK2 Ch. 3" },
  { "id": "NG3", "cat": "governance", "q": "Which role represents business executives who have the ultimate accountability for a specific data domain?", "options": ["Data Owners", "Data Stewards", "Data Custodians", "Data Governance Council", "Chief Information Officer"], "a": 0, "expl": "Data Owners are business executives who have the ultimate accountability for a specific data domain.", "prep": "DMBOK2 Ch. 3: Owners = Accountability.", "ref": "DMBOK2 Ch. 3" },
  { "id": "NG4", "cat": "governance", "q": "Who is specifically tasked with ensuring the accuracy and integrity of data and must maintain Data Dictionaries including a full change history?", "options": ["Data Stewards", "Data Owners", "Database Administrators", "Data Architects", "Data Quality Analysts"], "a": 0, "expl": "Data Stewards are responsible for the day-to-day management of data quality and metadata within their specific business areas.", "prep": "DMBOK2 Ch. 3: Stewards = day-to-day management.", "ref": "DMBOK2 Ch. 3" },
  { "id": "NG5", "cat": "governance", "q": "What often has a more direct impact on an organization than individual Data Stewards themselves because it automates the application of policy?", "options": ["A dynamic data classification system", "A master data management hub", "An enterprise data warehouse", "A data catalog tool", "A data quality dashboard"], "a": 0, "expl": "A dynamic data classification system automates the application of policy, having a direct impact.", "prep": "DMBOK2 Ch. 3: Dynamic classification = automated policy.", "ref": "DMBOK2 Ch. 3" },
  { "id": "NG6", "cat": "governance", "q": "Which metric is the prioritized metric for demonstrating the effectiveness of a Governance program?", "options": ["A percentage increase in data quality scores", "The number of data stewards appointed", "The volume of data cataloged", "The reduction in database storage costs", "The number of policies written"], "a": 0, "expl": "A percentage increase in data quality scores is the prioritized metric for demonstrating effectiveness.", "prep": "DMBOK2 Ch. 3: Metric = DQ score increase.", "ref": "DMBOK2 Ch. 3" },
  { "id": "NG7", "cat": "governance", "q": "The presence of documented policies indicates an organization is at which level of maturity?", "options": ["Defined (Level 3)", "Managed (Level 2)", "Optimizing (Level 5)", "Initial (Level 1)", "Predictable (Level 4)"], "a": 0, "expl": "Documented policies indicate the Defined level (Level 3).", "prep": "DMBOK2 Ch. 15: Defined = Documented policies.", "ref": "DMBOK2 Ch. 15" },
  { "id": "NG8", "cat": "governance", "q": "Which maturity state is characterized by success depending on specific projects, with processes being inconsistent across the broader organization?", "options": ["Managed (Level 2)", "Initial (Level 1)", "Defined (Level 3)", "Predictable (Level 4)", "Optimizing (Level 5)"], "a": 0, "expl": "Managed is the state when success depends on specific projects and processes are inconsistent.", "prep": "DMBOK2 Ch. 15: Managed = Project-dependent success.", "ref": "DMBOK2 Ch. 15" },
  { "id": "NG9", "cat": "governance", "q": "What provides the human accountability required for any governance framework?", "options": ["Stewardship and Ownership", "Data Quality Management", "Metadata Repositories", "Data Architecture", "Master Data Management"], "a": 0, "expl": "Stewardship and Ownership provide the human accountability required for any governance framework.", "prep": "DMBOK2 Ch. 3: Human accountability = Stewardship & Ownership.", "ref": "DMBOK2 Ch. 3" },
  { "id": "NME1", "cat": "metadata", "q": "What is the goal of the Metadata Management chapter?", "options": ["Ensuring that data is accurately defined", "Ensuring data is stored securely", "Ensuring data is integrated in real-time", "Ensuring data is archived properly", "Ensuring data models are normalized"], "a": 0, "expl": "The goal is ensuring that data is accurately defined. Metadata provides the essential context and meaning.", "prep": "DMBOK2 Ch. 12: Goal = accurately defined data.", "ref": "DMBOK2 Ch. 12" },
  { "id": "NME2", "cat": "metadata", "q": "Which standard is specifically for metadata registries?", "options": ["ISO/IEC 11179", "ISO 8000", "ISO 27001", "ISO 9001", "TOGAF"], "a": 0, "expl": "ISO/IEC 11179 is the standard for metadata registries.", "prep": "DMBOK2 Ch. 12: ISO 11179 = Metadata.", "ref": "DMBOK2 Ch. 12" },
  { "id": "NME3", "cat": "metadata", "q": "In metadata management, what describes the specific conditions or circumstances under which a value domain is applicable?", "options": ["Context", "Taxonomy", "Ontology", "Lineage", "Format"], "a": 0, "expl": "Context describes the specific conditions or circumstances under which a value domain is applicable.", "prep": "DMBOK2 Ch. 12: Context = conditions for value domain.", "ref": "DMBOK2 Ch. 12" },
  { "id": "NME4", "cat": "metadata", "q": "What are Data Catalog tools primarily used for?", "options": ["To manage and discover data assets across the enterprise", "To design physical database schemas", "To perform real-time data integration", "To encrypt sensitive data at rest", "To execute data quality cleansing rules"], "a": 0, "expl": "Data Catalog tools are primarily used to manage and discover data assets across the enterprise.", "prep": "DMBOK2 Ch. 12: Data Catalog = discover assets.", "ref": "DMBOK2 Ch. 12" },
  { "id": "NS1", "cat": "security", "q": "In the event of a Data Breach, what is the mandatory first action?", "options": ["Perform a Forensic Analysis", "Notify internal stakeholders", "Notify external customers", "Shut down all servers", "Restore data from backups"], "a": 0, "expl": "The mandatory first action is to perform a Forensic Analysis to ensure the source is understood and evidence is preserved.", "prep": "DMBOK2 Ch. 7: Breach response = Forensic Analysis first.", "ref": "DMBOK2 Ch. 7" },
  { "id": "NS2", "cat": "security", "q": "Which technique is prioritized for GDPR compliance when providing data to third parties while maintaining the ability to re-identify it later?", "options": ["Pseudonymization", "Anonymization", "Data Masking", "Encryption at rest", "Tokenization"], "a": 0, "expl": "Pseudonymization replaces private identifiers with artificial ones, keeping the re-identification key separate.", "prep": "DMBOK2 Ch. 7: Pseudonymization = re-identification possible.", "ref": "DMBOK2 Ch. 7" },
  { "id": "NMD1", "cat": "mdm", "q": "Which MDM pattern is the most lightweight and flexible approach, involving a central index of business keys while leaving descriptive data in source systems?", "options": ["Registry pattern", "Consolidated pattern", "Coexistence pattern", "Transaction pattern", "Centralized pattern"], "a": 0, "expl": "The Registry pattern is the most lightweight and flexible approach for MDM.", "prep": "DMBOK2 Ch. 10: Registry = lightweight index.", "ref": "DMBOK2 Ch. 10" },
  { "id": "NMD2", "cat": "mdm", "q": "For an MDM consolidation initiative, what is the most crucial first step?", "options": ["Map out the current data landscape and existing data silos", "Purchase an MDM software solution", "Define the golden record survivorship rules", "Migrate all data to a cloud data warehouse", "Establish a data governance council"], "a": 0, "expl": "The most crucial first step is to map out the current data landscape and existing data silos.", "prep": "DMBOK2 Ch. 10: Consolidation first step = map landscape.", "ref": "DMBOK2 Ch. 10" },
  { "id": "NMD3", "cat": "mdm", "q": "Which of the following is a recommended technical practice for performance tuning MDM loads?", "options": ["Use bulk data load utilities and disable indexes during the load process", "Use row-by-row inserts to ensure data integrity", "Enable all indexes during the load process", "Schedule data loads during peak usage hours", "Increase logging levels to maximum during the load"], "a": 0, "expl": "Performance tuning requires bulk loads, disabling indexes, parallel processing, and adjusting logging levels.", "prep": "DMBOK2 Ch. 10: MDM tuning = bulk load, disable indexes.", "ref": "DMBOK2 Ch. 10" },
  { "id": "NIQ1", "cat": "integration", "q": "What is a key component of data integration governance that ensures data flowing between systems meets required standards before being committed?", "options": ["Data validation rules", "Data encryption keys", "Data cataloging", "Data masking", "Data archiving"], "a": 0, "expl": "Data validation rules ensure data meets standards before it is committed to a target database.", "prep": "DMBOK2 Ch. 8: Validation rules = integration governance.", "ref": "DMBOK2 Ch. 8" },
  { "id": "NIQ2", "cat": "quality", "q": "Which technique is the primary method for gaining insights into missing values and data distribution patterns of individual fields?", "options": ["Column Profiling", "Cross-table Profiling", "Data Cleansing", "Entity Resolution", "Data Parsing"], "a": 0, "expl": "Column Profiling focuses on the characteristics of individual fields.", "prep": "DMBOK2 Ch. 13: Column Profiling = individual fields.", "ref": "DMBOK2 Ch. 13" }
]
